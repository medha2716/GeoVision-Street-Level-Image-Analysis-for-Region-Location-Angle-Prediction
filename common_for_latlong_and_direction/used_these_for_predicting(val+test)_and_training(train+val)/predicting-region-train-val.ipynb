{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9652aac8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-03T10:26:40.803984Z",
     "iopub.status.busy": "2025-05-03T10:26:40.803700Z",
     "iopub.status.idle": "2025-05-03T10:28:13.539285Z",
     "shell.execute_reply": "2025-05-03T10:28:13.537995Z"
    },
    "papermill": {
     "duration": 92.740124,
     "end_time": "2025-05-03T10:28:13.540538",
     "exception": false,
     "start_time": "2025-05-03T10:26:40.800414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/2522854220.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting regions for training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 205/205 [01:12<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting regions for validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 12/12 [00:04<00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predicted regions for training set to predicted_regions_train.csv\n",
      "Saved predicted regions for validation set to predicted_regions_val.csv\n",
      "\n",
      "Predicted Region ID distribution (Training):\n",
      "Region_ID\n",
      "1     361\n",
      "2     451\n",
      "3     444\n",
      "4     461\n",
      "5     484\n",
      "6     452\n",
      "7     392\n",
      "8     502\n",
      "9     262\n",
      "10    546\n",
      "11    403\n",
      "12    447\n",
      "13    397\n",
      "14    166\n",
      "15    774\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Predicted Region ID distribution (Validation):\n",
      "Region_ID\n",
      "1     21\n",
      "2     21\n",
      "3     28\n",
      "4     26\n",
      "5     28\n",
      "6     28\n",
      "7     22\n",
      "8     28\n",
      "9     14\n",
      "10    34\n",
      "11    21\n",
      "12    30\n",
      "13    24\n",
      "14     9\n",
      "15    35\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "dataset_folder = '/kaggle/input/smai-25-sec-a-project-phase-2-lat-long-prediction/'\n",
    "\n",
    "# Define paths - update these to your actual paths\n",
    "model_path = '/kaggle/input/best_convnext_model/pytorch/default/1/best_convnext_model.pth'  # Path to your saved model\n",
    "train_csv_path = dataset_folder+'labels_train.csv'  # Original training CSV\n",
    "val_csv_path = dataset_folder+'labels_val.csv'  # Original validation CSV\n",
    "train_img_dir = dataset_folder+'images_train/images_train'  # Training images directory\n",
    "val_img_dir = dataset_folder+'images_val/images_val'  # Validation images directory\n",
    "output_train_csv = 'predicted_regions_train.csv'  # Output predicted regions for training set\n",
    "output_val_csv = 'predicted_regions_val.csv'  # Output predicted regions for validation set\n",
    "\n",
    "# Load original data to maintain structure\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "\n",
    "# Image transformation for prediction (same as validation transform)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset class for prediction\n",
    "class PredictionDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.data_frame = csv_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.iloc[idx, 0]  # Assuming filename is in first column\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except:\n",
    "            print(f\"Error loading image: {img_path}\")\n",
    "            # Return a placeholder image in case of error\n",
    "            image = Image.new('RGB', (256, 256), color='gray')\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Return image and index (to map back to dataframe)\n",
    "        return image, idx\n",
    "\n",
    "# Create prediction datasets\n",
    "train_pred_dataset = PredictionDataset(train_df, train_img_dir, transform)\n",
    "val_pred_dataset = PredictionDataset(val_df, val_img_dir, transform)\n",
    "\n",
    "# DataLoaders for prediction\n",
    "batch_size = 32  # Can use larger batch size for prediction\n",
    "train_pred_loader = DataLoader(train_pred_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "val_pred_loader = DataLoader(val_pred_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load the model architecture (must match how it was defined during training)\n",
    "model = models.convnext_base(weights=None)  # No need to download weights\n",
    "num_ftrs = model.classifier[2].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    model.classifier[0],\n",
    "    model.classifier[1],\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(num_ftrs, 15)  # 15 regions (0-14 for PyTorch)\n",
    ")\n",
    "\n",
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def predict_regions(dataloader, dataframe):\n",
    "    \"\"\"Make region predictions for all images in dataloader\"\"\"\n",
    "    predictions = []\n",
    "    indices = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, idx in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            # Get predicted class (region)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            indices.extend(idx.numpy())\n",
    "    \n",
    "    # Convert from 0-14 back to 1-15 for Region_ID\n",
    "    predictions = [p + 1 for p in predictions]\n",
    "    \n",
    "    # Create a DataFrame with predictions\n",
    "    result_df = dataframe.copy()\n",
    "    result_df.loc[indices, 'Region_ID'] = predictions\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Predict regions for training set\n",
    "print(\"Predicting regions for training set...\")\n",
    "train_pred_df = predict_regions(train_pred_loader, train_df)\n",
    "\n",
    "# Predict regions for validation set\n",
    "print(\"Predicting regions for validation set...\")\n",
    "val_pred_df = predict_regions(val_pred_loader, val_df)\n",
    "\n",
    "# Save the predictions to CSV files\n",
    "train_pred_df.to_csv(output_train_csv, index=False)\n",
    "val_pred_df.to_csv(output_val_csv, index=False)\n",
    "\n",
    "print(f\"Saved predicted regions for training set to {output_train_csv}\")\n",
    "print(f\"Saved predicted regions for validation set to {output_val_csv}\")\n",
    "\n",
    "# Print region distribution in predictions for comparison\n",
    "print(\"\\nPredicted Region ID distribution (Training):\")\n",
    "print(train_pred_df['Region_ID'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nPredicted Region ID distribution (Validation):\")\n",
    "print(val_pred_df['Region_ID'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11893923,
     "sourceId": 99530,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 327528,
     "modelInstanceId": 307050,
     "sourceId": 370925,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 100.456746,
   "end_time": "2025-05-03T10:28:16.783954",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-03T10:26:36.327208",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
