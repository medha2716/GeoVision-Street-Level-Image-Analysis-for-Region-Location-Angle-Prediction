{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e714da73",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-03T17:34:36.286935Z",
     "iopub.status.busy": "2025-05-03T17:34:36.286670Z",
     "iopub.status.idle": "2025-05-03T17:34:58.838965Z",
     "shell.execute_reply": "2025-05-03T17:34:58.838019Z"
    },
    "papermill": {
     "duration": 22.55656,
     "end_time": "2025-05-03T17:34:58.840179",
     "exception": false,
     "start_time": "2025-05-03T17:34:36.283619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 369 test images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/2054844955.py:90: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting regions for test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 12/12 [00:04<00:00,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predicted regions for test set to predicted_regions_test.csv\n",
      "\n",
      "Predicted Region ID distribution (Test):\n",
      "Region_ID\n",
      "1     19\n",
      "2     22\n",
      "3     29\n",
      "4     26\n",
      "5     28\n",
      "6     28\n",
      "7     24\n",
      "8     26\n",
      "9     14\n",
      "10    30\n",
      "11    26\n",
      "12    27\n",
      "13    25\n",
      "14     9\n",
      "15    36\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# dataset_folder = '/kaggle/input/smai-25-sec-a-project-phase-2-lat-long-prediction/'\n",
    "\n",
    "# Define paths\n",
    "model_path = '/kaggle/input/best_convnext_model/pytorch/default/1/best_convnext_model.pth'  # Path to your saved model\n",
    "test_img_dir = '/kaggle/input/images-test/images_test'  # Test images directory (assuming this is what you have)\n",
    "output_test_csv = 'predicted_regions_test.csv'  # Output predicted regions for test set\n",
    "\n",
    "# Image transformation for prediction (same as validation transform)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to get all image filenames from a directory\n",
    "def get_image_filenames(directory):\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    filenames = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if any(filename.lower().endswith(ext) for ext in image_extensions):\n",
    "            filenames.append(filename)\n",
    "    \n",
    "    return sorted(filenames)\n",
    "\n",
    "# Get test image filenames\n",
    "test_filenames = get_image_filenames(test_img_dir)\n",
    "test_df = pd.DataFrame({'filename': test_filenames})\n",
    "print(f\"Found {len(test_df)} test images\")\n",
    "\n",
    "# Dataset class for prediction\n",
    "class PredictionDataset(Dataset):\n",
    "    def __init__(self, filenames, img_dir, transform=None):\n",
    "        self.filenames = filenames\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.filenames[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except:\n",
    "            print(f\"Error loading image: {img_path}\")\n",
    "            # Return a placeholder image in case of error\n",
    "            image = Image.new('RGB', (256, 256), color='gray')\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Return image and index (to map back to dataframe)\n",
    "        return image, idx\n",
    "\n",
    "# Create prediction dataset for test images\n",
    "test_pred_dataset = PredictionDataset(test_df['filename'].tolist(), test_img_dir, transform)\n",
    "\n",
    "# DataLoader for prediction\n",
    "batch_size = 32  # Can use larger batch size for prediction\n",
    "test_pred_loader = DataLoader(test_pred_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load the model architecture (must match how it was defined during training)\n",
    "model = models.convnext_base(weights=None)  # No need to download weights\n",
    "num_ftrs = model.classifier[2].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    model.classifier[0],\n",
    "    model.classifier[1],\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(num_ftrs, 15)  # 15 regions (0-14 for PyTorch)\n",
    ")\n",
    "\n",
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "def predict_regions(dataloader):\n",
    "    \"\"\"Make region predictions for all images in dataloader\"\"\"\n",
    "    predictions = []\n",
    "    indices = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, idx in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            # Get predicted class (region)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            indices.extend(idx.numpy())\n",
    "    \n",
    "    # Convert from 0-14 back to 1-15 for Region_ID\n",
    "    predictions = [p + 1 for p in predictions]\n",
    "    \n",
    "    return indices, predictions\n",
    "\n",
    "# Predict regions for test set\n",
    "print(\"Predicting regions for test set...\")\n",
    "indices, predictions = predict_regions(test_pred_loader)\n",
    "\n",
    "# Create result DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'filename': [test_df['filename'][i] for i in indices],\n",
    "    'Region_ID': predictions\n",
    "})\n",
    "\n",
    "# Save the predictions to CSV file\n",
    "result_df.to_csv(output_test_csv, index=False)\n",
    "\n",
    "print(f\"Saved predicted regions for test set to {output_test_csv}\")\n",
    "\n",
    "# Print region distribution in predictions\n",
    "print(\"\\nPredicted Region ID distribution (Test):\")\n",
    "print(result_df['Region_ID'].value_counts().sort_index())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11893923,
     "sourceId": 99530,
     "sourceType": "competition"
    },
    {
     "datasetId": 7320113,
     "sourceId": 11663951,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 327528,
     "modelInstanceId": 307050,
     "sourceId": 370925,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29.364034,
   "end_time": "2025-05-03T17:35:01.283792",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-03T17:34:31.919758",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
